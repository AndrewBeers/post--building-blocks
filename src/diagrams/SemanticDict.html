<:Window bind:innerWidth="winWidth" />

<div class="l-body">
  <div class="input_image">
    <img src="examples/input_images/{{example}}.png" alt="{{example}}" />

      <svg class="pointer_container" viewBox="0 0 {{N[0]}} {{N[1]}}">
        <filter id="background_rect_blur">
          <feGaussianBlur in="SourceGraphic" stdDeviation="0.02" />
        </filter>

        {{#each range(N[0]) as x}}
        {{#each range(N[1]) as y}}
          <rect x={{x}} y={{y}} width=1 height=1
            class={{(x == pos[0] && y == pos[1])? "selected" : "unselected"}}
            on:mouseover='set({pos: [x,y]})'></rect>
        {{/each}}
        {{/each}}

        <path d="{{pointer_line_path}}" class="pointer_line"  />
      </svg>
  </div>

  <div class="prose">
    <p>
      Making sense of these activations is hard because we usually work with them as abstract vectors:
    </p>
    
    <p id="abstract_vector">a<sub>{{pos[1]}},{{pos[0]}}</sub> = {{present_vector_str}}</p>
    
    <p>
      With feature visualization, however, we can transform this abstract vector into a more meaningful "semantic dictionary".
      Activations now map to interpretable iconic representations that we can explicitly name&mdash;for example "floppy ear," "dog snout," or "fluffy fur." This gives us a kind of "MRI for neural networks."
    </p>
  </div>
</div>

<div class="semantic_dict l-page">
  <span class="annotation">{</span>
  
  {{#each tops as top}}
    <Sprite src_class="sprite_mixed4d_neuron" n={{top[0]}} size="{{neuron_size}}" sprite_size="110" />

    <span class="colon annotation">:</span>

    <div class="value">
      <span style="bottom: {{top[1]/max_act*75}}px;">{{(top[1]+'').slice(0,4)}}</span>
      <div class="bar" style="height: {{top[1]/max_act*75}}px;"></div>
    </div>

    <span class="comma annotation">,</span>
  {{/each}}
  
  <span class="annotation"> ... }</span>
</div>

<style>

.input_image {
  position: relative;
  float: left;
  width: 224px;
  height: 224px;
  margin-right: 15px;
}

.input_image img, .input_image svg {
  position: absolute;
  width: 100%;
  height: 100%;
}

.pointer_container rect {
  opacity: 0;
}

.pointer_container .selected {
  opacity: 1;
  fill: rgba(255, 255, 255, 0.5);
  stroke: black;
  stroke-width: 0.01px;
}

.pointer_container .pointer_line {
  fill: none;
  stroke: rgba(255, 255, 255, 0.5);
  stroke-width: 0.1px;
}

#abstract_vector {
  display: inline-block;
  padding: 10px;
  background-color: hsl(0, 0%, 97%);
  border-top: 1px solid hsla(0, 0%, 0%, 0.1);
  border-bottom: 1px solid hsla(0, 0%, 0%, 0.1);
  width: calc(100% - 284px);
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

sub { font-size: 65%; }

.semantic_dict {
  display: flex;
  margin-top: 30px;
  align-items: center;
  justify-content: center;
  z-index: 100;
}

.semantic_dict .value {
  display: flex;
  position: relative;
  width: 25px;
  height: 75px;
  align-self: flex-end;
  font-size: 80%;
  color: #000;
  z-index: 100;
}

.semantic_dict .value span { position: absolute; }

.semantic_dict .bar {
  position: absolute;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: #ccc;
}

.semantic_dict span.annotation {
  font-size: 2em;
  font-weight: 300;
  color: #777;
}

.semantic_dict span:first-child {
  padding-left: 0;
  padding-right: 10px;
}

.semantic_dict span.colon { padding: 10px; }

.semantic_dict span.comma {
  padding-left: 10px;
  padding-right: 15px;
}
</style>

<script>
  import {argmax} from 'ndarray-ops';
  import Sprite from './Sprite.html'
  import {present_vector, range, tops, fmtAct} from '../util';

  function vector_y (N) {
    const p = document.querySelector('#SemanticDict #abstract_vector');
    const img = document.querySelector('#SemanticDict .input_image');
    if (!p || !img) return 2.5;

    const imgbb = img.getBoundingClientRect();
    const pbb = p.getBoundingClientRect();
    return (pbb.top - imgbb.top) / N[0] + 1;
  }
  
  export default {
    data() {
      return {
        N: [14, 14],
        pos: [2,3],
        max_act: undefined
      };
    },

    oncreate() {
      this.observe('example', (example) => {
        require(`../../static/examples/npy/${example}_mixed4d_activations.npy`).load((activation) => {
          this.set({activation});
        });
      });

      this.set({vector_y: vector_y(this.get('N'))});
    },

    computed: {
      max_act (activation) {
        if (!activation) return null;
        return activation.get(...argmax(activation))
      },

      pointer_line_path: (N, pos, vector_y) => {
        var start_y = Math.min(Math.max(1.7, pos[1]), pos[1]+1);
        var y_dist = Math.abs(start_y - vector_y);
        var main_x_start = Math.min(N[0] + 0.5, pos[0] + 1 + y_dist);  
        return `M ${pos[0]+1} ${start_y} L ${main_x_start} ${vector_y} L ${N[0]+1.5} ${vector_y}`
      },

      present_vector: (pos, activation) => present_vector(pos, activation),

      present_vector_str: (pos, present_vector) => {
        let s = '['    

        if (present_vector) {
          for (let n = 0; n < Math.min(12, present_vector.length); n++) {
            if (n > 0) s += ', ';
            s += fmtAct(present_vector[n]);
          }
        }

        return s + ', ...]';
      },

      tops: (present_vector) => tops(present_vector),

      vector_y: (winWidth, N) => vector_y(N),

      neuron_size (winWidth) {
        const div = document.querySelector('#SemanticDict .semantic_dict');
        if (!div) return 110;
        return ~~(div.getBoundingClientRect().width / 10);
      }
    },

    components: {Sprite},
    helpers: {range}
  }
</script>
